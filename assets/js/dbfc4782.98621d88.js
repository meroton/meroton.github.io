"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[8749],{1895:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"summer-buildbar-2024","metadata":{"permalink":"/blog/summer-buildbar-2024","editUrl":"https://github.com/meroton/docs/edit/main/blog/2024-06-13-summer-buildbar.mdx","source":"@site/blog/2024-06-13-summer-buildbar.mdx","title":"Summer Buildbar","description":"Before heads out to summer adventures I\'d like to invite everyone to a cool","date":"2024-06-13T00:00:00.000Z","tags":[{"inline":true,"label":"meroton","permalink":"/blog/tags/meroton"},{"inline":true,"label":"afterwork","permalink":"/blog/tags/afterwork"}],"readingTime":0.45,"hasTruncateMarker":false,"authors":[{"name":"Benjamin Ingberg","imageURL":"/img/benjamin-avatar.png","key":"benjamin","page":null}],"frontMatter":{"slug":"summer-buildbar-2024","title":"Summer Buildbar","authors":"benjamin","tags":["meroton","afterwork"]},"unlisted":false,"nextItem":{"title":"Automatically Reformat all Commits on a Branch","permalink":"/blog/Automatically-reformat-all-commits-on-a-branch"}},"content":"Before heads out to summer adventures I\'d like to invite everyone to a cool\\nsummer Buildbar. At the Buildbar we\'ll eat good food, talk about interesting\\ntechnical problems, new developments with Bazel and Buildbarn.\\n\\nAnd also have a few beers.\\n\\nFeel welcome to come over on Wednesday 19 June 2024, from 16 to 20.\\n\\n## Directions\\n\\nYou\'ll find us at our Link\xf6ping offices at Fridtunagatan 33. Currently there\\nis some ongoing construction but follow the red lines and you\'ll be fine.\\n\\n<figure>\\n  <img alt=\\"\\" src=\\"/img/office_map.webp\\" />\\n  <figcaption>Fridtunagatan 33 Link\xf6ping</figcaption>\\n</figure>"},{"id":"Automatically-reformat-all-commits-on-a-branch","metadata":{"permalink":"/blog/Automatically-reformat-all-commits-on-a-branch","editUrl":"https://github.com/meroton/docs/edit/main/blog/2023-12-22-rebase-and-reformat-git-branches-automatically.md","source":"@site/blog/2023-12-22-rebase-and-reformat-git-branches-automatically.md","title":"Automatically Reformat all Commits on a Branch","description":"If you have a formatter tool","date":"2023-12-22T00:00:00.000Z","tags":[{"inline":true,"label":"git","permalink":"/blog/tags/git"},{"inline":true,"label":"unix","permalink":"/blog/tags/unix"},{"inline":true,"label":"linting","permalink":"/blog/tags/linting"}],"readingTime":3.495,"hasTruncateMarker":false,"authors":[{"name":"Nils Wireklint","imageURL":"/img/nils-avatar.jpg","key":"nils","page":null}],"frontMatter":{"slug":"Automatically-reformat-all-commits-on-a-branch","title":"Automatically Reformat all Commits on a Branch","authors":"nils","tags":["git","unix","linting"]},"unlisted":false,"prevItem":{"title":"Summer Buildbar","permalink":"/blog/summer-buildbar-2024"},"nextItem":{"title":"Improved Chroot in Buildbarn","permalink":"/blog/improved-chroot-in-buildbarn"}},"content":"import Tabs from \'@theme/Tabs\';\\nimport TabItem from \'@theme/TabItem\';\\n\\n\\nIf you have a formatter tool\\nthat can rewrite your code\\nyou can run it automatically on all unmerged commits.\\nThis will show you how to script `git-rebase`\\nto do so without any conflicts.\\n\\nThere are two ways to do it manually, forward or backward.\\nThe forward pass amends each commit\\nand deals with the conflicts when stepping to the next commit.\\nIn contrast the backwards pass, formats each commit from the end,\\nwhich will avoid conflicts but for long commit chains it can be almost as boring.\\n\\nThis pattern comes up when working with long-lived feature branches,\\nor tasks that were almost done, and then pre-empted by other prioritized work.\\nHere are a few oneliners you can run to tidy up your commits.\\n\\nSee also the full technical guide for developing this `git-rebase` workflow\\nin [our documentation].\\nWhich contains more details on rebasing with `git`,\\nusing a scriptable editor to automate the `git-rebase` todo-list,\\nas well as the squashed commit messages.\\n\\n[our documentation]: /docs/practice/rebase-and-reformat-git-branches-automatically\\n[full technical guide]: /docs/practice/rebase-and-reformat-git-branches-automatically\\n\\n## Example commits\\n\\nSay you have three unmerged commits:\\n\\n    21cc7b5 My amazing feature\\n    e05fd9f Other complimentary work\\n    acb9fae Fix annoying bug\\n\\nThey contain important work, but you forgot to run some linters,\\nor the main branch added more lint requirements\\nafter the feature work was started.\\nThis will run linters that can automatically fix issues on each commit\\nthrough a scripted `git-rebase`.\\n\\n## Rebase algorithm\\n\\nWe have a three-step process to update each commit.\\n\\n* 1: Create a fixup commit with the applied lint suggestions,\\n  which we immediately revert\\n  so the next commit still applies\\n\\n  ```bash title=reformat.sh\\n  #!/bin/sh\\n\\n  # Formatters and fixers go here.\\n  # Replace with your tools of choice! rustfmt, gofmt, black, ...\\n  ./run-all-linters-and-autofixers.sh\\n\\n  # Add a new commit with the changes and revert it again.\\n  git add -u\\n  git commit --allow-empty --fixup HEAD\\n  # \'git-revert\' does not support \'--allow-empty\'.\\n  git revert --no-commit HEAD\\n  git commit --allow-empty --no-edit\\n  ```\\n\\n* 2: Squash the fixup commit into the original feature commit\\n\\n* 3: Squash the revert down into the next feature commit\\n\\nThese tabs show how the commits evolve and are squashed,\\nthe extra commits are grouped to indicate the target commit.\\nThe revert of the first commit is grouped with the second feature commit,\\nand so on.\\nWe discard the final revert.\\n\\n<Tabs>\\n<TabItem value=\\"original\\" label=\\"Original\\">\\n\\n```\\n21cc7b5 My amazing feature\\n\\n\\n\\ne05fd9f Other complimentary work\\n\\n\\n\\nacb9fae Fix annoying bug\\n\\n\\n\\n```\\n\\n</TabItem>\\n<TabItem value=\\"reformated\\" label=\\"1: Reformated\\" default>\\n\\n```\\n21cc7b5 My amazing feature\\n01900c5 fixup! My amazing feature\\n\\n55feaba Revert \\"fixup! My amazing feature\\"\\ne05fd9f Other complimentary work\\nd122da7 fixup! Other complimentary work\\n\\n249b0d3 Revert \\"fixup! Other complimentary work\\"\\nacb9fae Fix annoying bug\\n50e426a fixup! Fix annoying bug\\n\\n7e84259 Revert \\"fixup! Fix annoying bug\\"\\n```\\n\\n</TabItem>\\n<TabItem value=\\"fixed-up\\" label=\\"2: Fixed-up\\" default>\\n\\n```\\n9ed9557 My amazing feature\\n\\n\\n55feaba Revert \\"fixup! My amazing feature\\"\\n0db521b Other complimentary work\\n\\n\\n249b0d3 Revert \\"fixup! Other complimentary work\\"\\ne2e991b Fix annoying bug\\n\\n\\n7e84259 Revert \\"fixup! Fix annoying bug\\"\\n```\\n\\n</TabItem>\\n<TabItem value=\\"fully-squashed\\" label=\\"3: Fully-squashed\\" default>\\n\\n```\\n9ed9557 My amazing feature\\n\\n\\n\\n8e76352 Other complimentary work\\n\\n\\n\\nf286036 Fix annoying bug\\n\\n\\n\\n```\\n\\n</TabItem>\\n</Tabs>\\n\\n## Oneliners\\n\\n`git` allows us to set any editor to edit the todo-list, `$GIT_SEQUENCE_EDITOR`,\\nand the commit message, `$EDITOR`.\\nWe choose `vim` as it is often available, and easier to use than `sed` and `awk`.\\nIt is nice to have a _scriptable_ interactive editor\\nto make changes to the workflow and try out the commands.\\n\\nSee the [full technical guide] for details and more tips on `git-rebase` and `vim`.\\n\\n\\nReformat:\\n```\\n$ env                          \\\\\\n    GIT_SEQUENCE_EDITOR=\\"true\\" \\\\\\n    git rebase -i --exec ./reformat.sh origin/main\\n```\\nFixup (autosquash):\\n```\\n# More robust autosquash, that handles duplicated commit messages.\\n# If your commit messages are all unique you can use \'--autosquash\' instead.\\n# See the technical guide for more details.\\n$ env                                                             \\\\\\n    GIT_SEQUENCE_EDITOR=\\"vim +\'g/^\\\\w* \\\\w* fixup!/s/^pick/fixup/\'\\" \\\\\\n    git rebase -i origin/main\\n```\\nSquash:\\n```\\n$ env                                                                                               \\\\\\n    EDITOR=\\"sed -i \'1,9d\'\\"                                                                          \\\\\\n    GIT_SEQUENCE_EDITOR=\\"vim +\'g/^#/d\' +\'normal! Gdk\' +\'g/^pick \\\\w* Revert \\\\\\"fixup!/normal! j0ces\'\\" \\\\\\n    git rebase -i origin/main\\n```\\n\\n:::info\\nWe have not developed the *incantation*, `git-rebase` command,\\nto preserve the author date from the original commits.\\nWe will address that next!\\n:::"},{"id":"improved-chroot-in-buildbarn","metadata":{"permalink":"/blog/improved-chroot-in-buildbarn","editUrl":"https://github.com/meroton/docs/edit/main/blog/2023-12-01-improved-chroot-in-buildbarn.mdx","source":"@site/blog/2023-12-01-improved-chroot-in-buildbarn.mdx","title":"Improved Chroot in Buildbarn","description":"We have just started a documentation series","date":"2023-12-01T00:00:00.000Z","tags":[{"inline":true,"label":"linux","permalink":"/blog/tags/linux"},{"inline":true,"label":"syscalls","permalink":"/blog/tags/syscalls"},{"inline":true,"label":"buildbarn","permalink":"/blog/tags/buildbarn"}],"readingTime":0.655,"hasTruncateMarker":false,"authors":[{"name":"Nils Wireklint","imageURL":"/img/nils-avatar.jpg","key":"nils","page":null}],"frontMatter":{"slug":"improved-chroot-in-buildbarn","title":"Improved Chroot in Buildbarn","authors":"nils","tags":["linux","syscalls","buildbarn"]},"unlisted":false,"prevItem":{"title":"Automatically Reformat all Commits on a Branch","permalink":"/blog/Automatically-reformat-all-commits-on-a-branch"},"nextItem":{"title":"Updates to Buildbarn as of November 2023","permalink":"/blog/buildbarn-updates-2023-11"}},"content":"We have just started a documentation series\\ndescribing the Buildbarn `chroot` runners,\\nand how they can be used for hermetic input roots\\nthat contain all the required tools.\\nThis includes implementation notes for a \\"mountat\\" functionality\\ncreated through the new Linux mount API,\\nhow you can use this under-documented API\\nand its shortcomings.\\nAnd how this _can/will be_ integrated into Buildbarn,\\nwith technical descriptions of the workers and runners.\\n\\nThe first sections are already available, with more to come!\\n\\nSections:\\n\\n* [Use chroot in Buildbarn]\\n* [Implement mountat with the new mount API]\\n* [Unmount from relative file paths and directory file descriptors]\\n\\nReference code repository:\\n\\n* https://github.com/meroton/prototype-mountat/\\n\\n[Implement mountat with the new mount API]: /docs/improved-chroot-in-buildbarn/implementing-mountat/\\n[Unmount from relative file paths and directory file descriptors]: /docs/improved-chroot-in-buildbarn/implementing-unmountat/\\n[Use chroot in Buildbarn]: /docs/improved-chroot-in-buildbarn/chroot-in-buildbarn/"},{"id":"buildbarn-updates-2023-11","metadata":{"permalink":"/blog/buildbarn-updates-2023-11","editUrl":"https://github.com/meroton/docs/edit/main/blog/2023-11-21-buildbarn-updates.mdx","source":"@site/blog/2023-11-21-buildbarn-updates.mdx","title":"Updates to Buildbarn as of November 2023","description":"This is a continuation of the","date":"2023-11-21T00:00:00.000Z","tags":[{"inline":true,"label":"release","permalink":"/blog/tags/release"},{"inline":true,"label":"buildbarn","permalink":"/blog/tags/buildbarn"}],"readingTime":1.795,"hasTruncateMarker":false,"authors":[{"name":"Benjamin Ingberg","imageURL":"/img/benjamin-avatar.png","key":"benjamin","page":null}],"frontMatter":{"slug":"buildbarn-updates-2023-11","title":"Updates to Buildbarn as of November 2023","authors":"benjamin","tags":["release","buildbarn"]},"unlisted":false,"prevItem":{"title":"Improved Chroot in Buildbarn","permalink":"/blog/improved-chroot-in-buildbarn"},"nextItem":{"title":"Memory Adventure","permalink":"/blog/memory-adventure"}},"content":"This is a continuation of the\\n[previous update article](/blog/bb-deployments-updates-2023-02)\\nand is a high level summary of what has happened in Buildbarn from 2023-02-16 to 2023-11-14.\\n\\n## Added support for JWTs signed with RSA\\n\\nSupport for JWTs signed with RSA has been added.\\nThe following JWT signing algorithms are now supported:\\n\\n- HS256\\n- HS384\\n- HS512\\n- RS256\\n- RS384\\n- RS512\\n- EdDSA\\n- ES256\\n- ES384\\n- ES512\\n\\n## Generalized tuneables for Linux BDI options\\n\\nLinux 6.2 added a sysfs attribute for toggling `BDI_CAP_STRICTLIMIT` on FUSE mounts.\\nIf using the FUSE backed virtual file system on Linux 6.2\\nadding `{ \\"strict_limit\\": \\"0\\" }` to `linux_backing_dev_info_tunables`\\nwill remove the `BDI_CAP_STRICTLIMIT` flag from the FUSE mount.\\n\\nThis may improve fileystem performance\\nespecially when running build actions which\\nuses mmap\'ed files extensively.\\n\\n## Add support for injecting Xcode environment variables\\n\\nRemote build with macOS may call into locally installed copies of Xcode.\\nThe path to the local copy of Xcode may vary\\nand Bazel assumes that the remote execution service\\nis capable of processing Xcode specific environment variables.\\n\\nSee the [proto files](https://github.com/buildbarn/bb-remote-execution/blob/master/pkg/proto/configuration/bb_runner/bb_runner.proto#L133) for details.\\n\\n## Add a minimum timestamp to ActionResultExpiringBlobAccess\\n\\nA misbehaving worker may polluted the action cache,\\nafter fixing the misbehaving worker\\nwe would rather not throw away the entire action cache.\\n\\nA minimum timestamp in ActionResultExpiringBlobAccess\\nallows us to mark a timestamp in the past\\nbefore which the action should be considered invalid.\\n\\n## Add authentication to HTTP servers\\n\\nMuch like the gRPC servers are capable of authenticated configuration\\nthe http servers can now also require authentication.\\n\\nThis allows the bb_browser and bb_scheduler UI\\nto authenticate access using OAuth2 without involving any other middleware.\\n\\nThis also allows us to add authorization configuration for administrative tasks\\nsuch as draining workers or killing of jobs.\\n\\n## Authentication using a JSON Web Key Set\\n\\nJSON Web Key Sets (JWKS) is a standard format\\nwhich allows us to specify multiple different encryption keys\\nthat may have been used to sign our JWT authentication.\\n\\nBuildbarn can load the JWKS specification,\\neither inline or as a file,\\nwhen specifying trusted encryption keys.\\n\\nThis allows us to have rotation with overlap of encryption keys."},{"id":"memory-adventure","metadata":{"permalink":"/blog/memory-adventure","editUrl":"https://github.com/meroton/docs/edit/main/blog/2023-11-13-memory-adventure/2023-11-13-adventure.mdx","source":"@site/blog/2023-11-13-memory-adventure/2023-11-13-adventure.mdx","title":"Memory Adventure","description":"An adventure in finding a memory thief in Starlark-land","date":"2023-11-13T00:00:00.000Z","tags":[{"inline":true,"label":"bazel","permalink":"/blog/tags/bazel"},{"inline":true,"label":"buildbarn","permalink":"/blog/tags/buildbarn"}],"readingTime":7.945,"hasTruncateMarker":false,"authors":[{"name":"Nils Wireklint","imageURL":"/img/nils-avatar.jpg","key":"nils","page":null}],"frontMatter":{"slug":"memory-adventure","title":"Memory Adventure","authors":"nils","tags":["bazel","buildbarn"]},"unlisted":false,"prevItem":{"title":"Updates to Buildbarn as of November 2023","permalink":"/blog/buildbarn-updates-2023-11"},"nextItem":{"title":"BazelCon 2023","permalink":"/blog/bazelcon-2023"}},"content":"An adventure in finding a memory thief in Starlark-land\\n\\nThis is a summary and follow-up to [my talk] at BazelCon-2023.\\nWith abridged code examples, the full instructions are available [together with the code].\\n\\n[my talk]: https://www.youtube.com/watch?v=IXimf4DCAoY#t=7h21m57s\\n[together with the code]: https://github.com/meroton/memory-adventure\\n\\n## Problem Statement\\n\\nFirst, we lament Bazel\'s out-of-memory errors,\\n  and point out that the often useful Starlark stacktrace does not always show up.\\nSome allocation errors just crash Bazel without giving and indication of which allocation failed.\\n\\n![allocation](./memory-allocation-failure.png)\\n\\nThis diagram illustrates a common problem for memory errors,\\nthe allocation that fails may not be the problem,\\nit is just the straw that breaks the camel\'s back.\\nAnd the real thief may already have allocated its memory.\\n\\nWe have seen many errors when working with clients,\\nand they typically hide in big corporate code bases.\\nWhich complicates troubleshooting, discussion and error reporting.\\nSo we create a synthetic repository to try to illustrate the problem,\\nand have something to discuss.\\nThe code and instructions are available [here].\\n\\nErrors and poor performance in the analysis phase\\nare not good at all.\\nThis is because the analysis must always be done\\nbefore starting to build all actions.\\nWith big projects the number of configuration to build for can be very large,\\nso one cannot rely on CI runners to build the same configuration over and over,\\nto retain the analysis cache.\\nInstead it is on the critical-path for all builds,\\nespecially if the actions themselves are cached remotely.\\n\\nTo illustrate (some of the problem) we have a reproduction repository\\nwith example code base with some Python and C programs.\\nTo introduce memory problems, and make it a little more complex\\nwe add two rules: one CPU intensive rule (\\"spinlock\\")\\nand one memory intensive aspect (\\"traverse\\").\\nThe \\"traverse\\" aspect encodes the full dependency tree of all targets\\nand writes that to a file with `ctx.actions.write`.\\nSo the allocations are tied to the Action object.\\n\\n[here]: https://github.com/meroton/memory-adventure\\n\\n## Toolbox\\n\\nWe have a couple of tools available, many are discussed in the [memory optimization guide],\\nbut we find that some problems can slip through the cracks.\\n\\nFirst off, there are the post-build analysis tools in bazel:\\n\\n  * `bazel info`\\n  * `bazel dump --rules`\\n  * `bazel aquery --skyframe_state`\\n\\nThese are a good starting point and have served us well on many occasions.\\nBut with this project they seem to miss some allocations\\nWe will return to that later.\\nAdditionally, these tool will not give any information if the Bazel server crashes.\\nYou will need to increase the memory and run the same build again.\\n\\nThen one can use Java tools to inspect what the JVM is doing:\\n\\n  * [Eclipse Memory Analyzer]\\n  * `jmap`\\n\\nThe best approach here is to ask Bazel to save the heap if it crashes,\\nso it can be analyzed post-mortem: `bazel --heap_dump_on_oom`\\n\\nAnd lastly, use Bazel\'s profiling information:\\n\\n  * `bazel --profile=profile.gz --generate_json_trace_profile --noslim_profile`\\n\\nThis contains structured information\\nand is written continuously to disk,\\nso if Bazel crashes we can still parse it,\\nwe just need to discard partially truncated events.\\n\\n[Eclipse Memory Analyzer]: https://eclipse.dev/mat/documentation/\\n[memory optimization guide]: https://bazel.build/rules/performance#memory-profiling\\n\\n## Expected Memory consumption\\n\\nAs the two rules write their string allocations to output files\\nwe get a clear picture of the expected RAM usage (or at least a lower bound).\\n\\n```\\n$ bazel clean\\n$ bazel build \\\\\\n  --aspects @example//memory:eat.bzl%traverse \\\\\\n  --output_groups=default,eat_memory \\\\\\n  //...\\n# Memory intensive tree traversal (in KB)\\n$ find bazel-out/ -name \'*.tree\' | xargs du | cut -f1 | paste -sd \'+\' | bc\\n78504\\n# CPU intensive spinlocks (in KB)\\n$ find bazel-out/ -name \'*.spinlock\' | xargs du | cut -f1 | paste -sd \'+\' | bc\\n3400\\n```\\n\\nHere is a table with the data:\\n\\n|  | Memory for each target | Total |\\n| ---- | ---- | ----------- |\\n| Memory intensive | 0-17 MB | 79 MB |\\n| CPU intensive | 136 KB |  3.4 MB |\\n\\n## Reported Memory Consumption\\n\\nNext, we check with the diagnostic tools.\\n\\n```\\n$ bazel version\\nBazelisk version: development\\nBuild label: 6.4.0\\n```\\n\\n### Bazel dump --rules\\n\\n```\\n$ bazel $STARTUP_FLAGS --host_jvm_args=-Xmx\\"10g\\" dump --rules\\nWarning: this information is intended for consumption by developers\\nonly, and may change at any time. Script against it at your own risk!\\n\\nRULE                              COUNT     ACTIONS          BYTES         EACH\\ncc_library                            4          17        524,320      131,080\\nnative_binary                         1           4        524,288      524,288\\ncc_binary                             6          54        262,176       43,696\\ntoolchain_type                       14           0              0            0\\ntoolchain                            74           0              0            0\\n...\\n\\nASPECT                             COUNT     ACTIONS          BYTES         EACH\\ntraverse                              85          81        262,432        3,087\\nspinlock14                            35          66        524,112       14,974\\nspinlock15                            35          66              0            0\\n...\\n```\\n\\nFirst, there are some common rules that we do not care about here,\\nthen we have the Aspects.\\n`traverse` is the memory intensive aspect,\\nwhich is applied on the command line\\nand `spinlock<N>` are the CPU intensive rules,\\nwith identical implementations just numbered (there are 25 of them).\\n\\nIt is a little surprising that only one have allocations.\\nAnd the action count for each aspect does not make sense either,\\nas this is not a transitive aspect.\\nIt just runs a single action each time the rule is instantiated.\\nThe hypothesis is that this is a display problem,\\nwith code shared between rules.\\nThere are 25 rules, with 25 distinct implementation functions,\\nbut they in turn call the same function with the action.\\nSo the \\"count\\" and \\"actions\\" columns are glued together,\\nbut the \\"bytes\\" is reported for just one of the rules (it would be bad if this was double-counted).\\n\\nEither way,\\nthe total number of bytes does not add up to what we expect.\\nCompare the output to the lower-bound determined before:\\n\\n|  | Memory for each target | Total | Reported Total |\\n| ---- | ---- | ----------- |\\n| Memory intensive | 0-17 MB | 79 MB | 262 kB\\n| CPU intensive | 136 KB |  3.4 MB | 524 kB\\n\\n### Skylark Memory Profile\\n\\n:::info\\nThis is not part of the video.\\n:::\\n\\nThe skylark memory profiler is much more advanced,\\nand can be dumped after a successful build.\\n\\n```\\n$ bazel $STARTUP_FLAGS --host_jvm_args=-Xmx\\"$mem\\" dump \\\\\\n    --skylark_memory=\\"$dir/memory.pprof\\"\\n```\\n\\n```\\n$ pprof manual/2023-10-30/10g-2/memory.pprof\\nMain binary filename not available.\\nType: memory\\nTime: Oct 30, 2023 at 12:16pm (CET)\\nEntering interactive mode (type \\"help\\" for commands, \\"o\\" for options)\\n(pprof) top\\nShowing nodes accounting for 2816.70kB, 73.34% of 3840.68kB total\\nShowing top 10 nodes out of 19\\n      flat  flat%   sum%        cum   cum%\\n     512kB 13.33% 13.33%      512kB 13.33%  impl2\\n  256.16kB  6.67% 20.00%   256.16kB  6.67%  traverse_impl\\n  256.11kB  6.67% 26.67%   256.11kB  6.67%  _add_linker_artifacts_output_groups\\n  256.09kB  6.67% 33.34%   256.09kB  6.67%  alias\\n  256.09kB  6.67% 40.00%   256.09kB  6.67%  rule\\n  256.08kB  6.67% 46.67%   256.08kB  6.67%  to_list\\n  256.06kB  6.67% 53.34%   256.06kB  6.67%  impl7\\n  256.04kB  6.67% 60.01%   256.04kB  6.67%  _is_stamping_enabled\\n  256.04kB  6.67% 66.67%   256.04kB  6.67%  impl18\\n  256.03kB  6.67% 73.34%   768.15kB 20.00%  cc_binary_impl\\n```\\n\\nHere the Memory intensive aspect shows up with 256kB,\\nwhich is inline with the output from `bazel dump --rules`,\\nbut not reflecting the big allocations we know it makes.\\n\\n### Eclipse Memory Analyzer\\n\\nThe final tool we have investigated is the Java heap analysis tool\\n[Eclipse Memory Analyzer],\\nwhich can easily be used with Bazel\'s `--heap_dump_on_oom` flag.\\nOn the other hand it is a little tricker to find a heap dump from a successful build.\\n\\n![eclipse-analysis](./eclipse-memory-analyzer.png)\\n\\nHere we see the (very) big allocation clear as day,\\nbut have no information of its provenance.\\n\\nWe have not found how to track this back to a Skylark function, Skyframe evaluator\\nor anything that could be cross-referenced with the profiling information.\\n\\n## Build Time\\n\\nThe next section of the talk shows the execution time of the build\\nwith varying memory limits.\\n\\n![combined](./build-time-memory-plot.png)\\n\\nThis is benchmarked with 5 data points for each memory limit,\\nand the plot shows failure if there was at least one crash among the data points.\\nThere is a region where the build starts to succeed more and more often, but sometimes crashes.\\nSo the Crash and not-crash graphs overlap a little,\\nyou want to have some leeway to avoid flaky builds from occasional out-of-memory crashes.\\n\\nWe see that the Skymeld graph requires a lot less memory than a regular build,\\nthat is because our big allocations are all tied to Action objects.\\nEnabling Skymeld lets Bazel start executing Actions as soon as they are ready,\\nso the resident set of Action objects does not grow so large,\\nand the allocations can be freed much sooner.\\n\\n## Pessimization with limited memory\\n\\n![pessimization](./low-memory-pessimization.png)\\n\\nWe saw a hump in the build time for the Skymeld graph,\\nwhere the builds did succeed in the 300 - 400 MB range,\\nbut the build speed gradually increased, reaching a plateau at around 500 MB.\\nThis is a pattern we have seen before,\\nwhere more RAM, or more efficient rules can improve build performance.\\n\\nThis is probably because the memory pressure and the Java Garbage Collector\\ninterferes with the Skyframe work.\\nSee [Benjamin Peterson\'s great talk] about the Skyframe for more information.\\n\\n[Benjamin Peterson\'s great talk]: https://www.youtube.com/watch?v=8Dc8R_Zrf6M&t=3039s\\n\\n## Future work\\n\\n![example profile](./example-chrome-tracing.png)\\n\\nThis section details future work for more tools and signals\\nthat we can find from Bazel\'s profile information\\n`--profile=profile.gz --generate_json_trace_profile --noslim_profile`.\\nWritten in the standard `chrome://tracing` format\\nit is easy to parse for both successful and failed builds.\\n\\nThis contains events for the garbage collector,\\nand all executed Starlark functions.\\n\\nThese can be correlated\\nto find which functions are active during, or before, garbage collection events.\\nAdditionally, one could collect this information for all failed builds,\\nand see if some functions are overrepresented\\namong the last active functions for each evaluator in the build."},{"id":"bazelcon-2023","metadata":{"permalink":"/blog/bazelcon-2023","editUrl":"https://github.com/meroton/docs/edit/main/blog/2023-11-02-bazelcon-2023.mdx","source":"@site/blog/2023-11-02-bazelcon-2023.mdx","title":"BazelCon 2023","description":"Meroton visited BazelCon 2023 in Munich October 24-25, 2023.","date":"2023-11-02T00:00:00.000Z","tags":[{"inline":true,"label":"bazel","permalink":"/blog/tags/bazel"},{"inline":true,"label":"buildbarn","permalink":"/blog/tags/buildbarn"}],"readingTime":0.775,"hasTruncateMarker":false,"authors":[{"name":"Fredrik Medley","imageURL":"/img/fredrik-avatar.png","key":"fredrik","page":null}],"frontMatter":{"slug":"bazelcon-2023","title":"BazelCon 2023","authors":"fredrik","tags":["bazel","buildbarn"]},"unlisted":false,"prevItem":{"title":"Memory Adventure","permalink":"/blog/memory-adventure"},"nextItem":{"title":"Buildbarn Block Sizes","permalink":"/blog/buildbarn-block-sizes"}},"content":"Meroton visited BazelCon 2023 in Munich October 24-25, 2023.\\nDuring the conference, we held three talks:\\n* [Remote Output Service - How not to have your bytes and eat them too](https://www.youtube.com/watch?v=8Dc8R_Zrf6M#t=7h36m20s)\\n  by Benjamin Ingberg about bb_clientd and the Remote Output Service.\\n* [Buildbarn - From 100 to 100.000 CPUs](https://www.youtube.com/watch?v=IXimf4DCAoY#t=3h2m10s)\\n  ([slides](https://docs.google.com/presentation/d/14qgMa1J9hBMTU017PlpQokKtS5n0KxJbJXPjndxqPqE/edit?usp=sharing&resourcekey=0-OF3Hrwvr5G7aDnJG_ABRhw))\\n  by Fredrik Medley.\\n* [Dude, where is my RAM? - An adventure in finding a RAM thief in Starlak land](https://www.youtube.com/watch?v=IXimf4DCAoY#t=7h21m57s)\\n  by Nils Wireklint about difficulties in debugging out-of-memory errors in Bazel.\\n\\nOther talks that mentioned Buildbarn were:\\n* [Migrating a Multiple-Platform Game Engine to Bazel](https://www.youtube.com/watch?v=8Dc8R_Zrf6M#t=5h41m5s)\\n  where Kai Zhang from NetEase talks about a\\n  [Buildbarn worker implementation in Python for Windows and MacOS](https://github.com/kkpattern/bb-remote-execution-py).\\n* [Planting Bazel in barren soil: A Perl Story](https://www.youtube.com/watch?v=8Dc8R_Zrf6M#t=7h56m2s)\\n  where Manuel Naranjo from Booking.com is using Buildbarn for remote execution and Buildbuddy for Build Event Streaming.\\n\\nWe are thankful for all amazing chats with the community and are looking forward to BazelCon 2024."},{"id":"buildbarn-block-sizes","metadata":{"permalink":"/blog/buildbarn-block-sizes","editUrl":"https://github.com/meroton/docs/edit/main/blog/2023-04-11-buildbarn-block-size/2023-04-11-buildbarn-block-size.md","source":"@site/blog/2023-04-11-buildbarn-block-size/2023-04-11-buildbarn-block-size.md","title":"Buildbarn Block Sizes","description":"When starting out with remote caching,","date":"2023-04-11T00:00:00.000Z","tags":[{"inline":true,"label":"buildbarn","permalink":"/blog/tags/buildbarn"}],"readingTime":2.53,"hasTruncateMarker":false,"authors":[{"name":"Benjamin Ingberg","imageURL":"/img/benjamin-avatar.png","key":"benjamin","page":null}],"frontMatter":{"slug":"buildbarn-block-sizes","title":"Buildbarn Block Sizes","authors":"benjamin","tags":["buildbarn"]},"unlisted":false,"prevItem":{"title":"BazelCon 2023","permalink":"/blog/bazelcon-2023"},"nextItem":{"title":"Updates to Buildbarn deployment repo as of Febuary 2023","permalink":"/blog/bb-deployments-updates-2023-02"}},"content":"When starting out with remote caching,\\nan error you are likely to run into is:\\n\\n```\\njava.io.IOException: com.google.devtools.build.lib.remote.ExecutionStatusException:\\nINVALID_ARGUMENT: Failed to store previous blob 1-<HASH>-<LARGE_NUM>:\\nShard 1: Blob is <LARGE_NUM> bytes in size,\\nwhile this backend is only capable of storing blobs of up to 238608384 bytes in size\\n```\\n\\nThis is because your storage backend is too small.\\nYou are attempting to upload a blob larger than the largest blob accepted by your storage backend.\\n\\n## How do I fix it?\\n\\nThe largest blob you can store is the size of your your storage device\\ndivided by the number of blocks in your device.\\n\\nTo store larger blobs,\\neither increase the size of your storage device\\nor decrease the number of blocks it is split into. \\nLarger storage devices will take more disk,\\nwhile fewer blocks will decrease the granularity which your cache works with.\\n\\nIn\\n[bb-deployments](https://github.com/buildbarn/bb-deployments)\\nthis setting is found in\\n[storage.jsonnet](https://github.com/buildbarn/bb-deployments/blob/d63c032b2b4d96f93cb889f95add15c26118d771/docker-compose/config/storage.jsonnet).\\n\\n```js\\n{\\n  // ...\\n  contentAddressableStorage: {\\n    backend: {\\n      \'local\': {\\n        // ...\\n        oldBlocks: 8,\\n        currentBlocks: 24,\\n        newBlocks: 1,\\n        blocksOnBlockDevice: {\\n          source: {\\n            file: {\\n              path: \'/storage-cas/blocks\',\\n              sizeBytes: 8 * 1024 * 1024 * 1024, // 8GiB\\n            },\\n          },\\n          spareBlocks: 3,\\n        },\\n        // ...\\n      },\\n    },\\n  },\\n  // ...\\n}\\n```\\n\\nTo facilitate getting started bb-deployments emulates a block device by using an 8GiB large file.\\nThis file is small enough to fit most builds while not taking over the disk completely from a developers machine.\\n\\nThe device is then split into 36 blocks (8+24+1+3),\\nwhere each block can then store a maximum of 238608384 bytes (8GiB / 36 - some alignment).\\n\\nIn production it is preferable to use a large raw block device for this purpose.\\n\\n## What does new/old/current/spare mean?\\n\\nIn depth documentation about all the settings are available in the\\n[configuration proto files](https://github.com/buildbarn/bb-storage/blob/master/pkg/proto/configuration/blobstore/blobstore.proto).\\n\\nIn essence the storage works as a ringbuffer where the assignment of each block is rotated. \\nConsider a 5 block configuration with 1 old, 2 current, 1 new and 1 spare block.\\n\\n![diagram](./2023-04-11-buildbarn-block-size-1.svg)\\n\\nAs data is referenced from an old block\\nit gets written into a new block.\\nWhen the new block is full the role rotates.\\n\\n\\n![diagram](./2023-04-11-buildbarn-block-size-2.svg)\\n\\nThere are some tradeoffs in behaviour to consider when choosing your block layout. Fewer blocks will allow larger individual blobs at the cost of granularity. Here is a quick summary of the meaning of the different fields.\\n\\n* **Old** - Region where reads are actively copied over to new, too small value and your device behaves more like a FIFO than a LRU cache, too large and your device does a lot of uneccesary copying.\\n* **Current** - Stable region, should be the majority of your device.\\n* **New** - Region for writing new data to, must be 1 for AC and should be 1-4 for CAS. Having a couple of new blocks allows data to be better spread out over the device so as to not expire at the same time.\\n* **Spare** - Region for giving ongoing reads some time to finish before data starts getting overwritten."},{"id":"bb-deployments-updates-2023-02","metadata":{"permalink":"/blog/bb-deployments-updates-2023-02","editUrl":"https://github.com/meroton/docs/edit/main/blog/2023-02-21-updates-to-bb-deployments.mdx","source":"@site/blog/2023-02-21-updates-to-bb-deployments.mdx","title":"Updates to Buildbarn deployment repo as of Febuary 2023","description":"The example configuration project for buildbarn","date":"2023-02-21T00:00:00.000Z","tags":[{"inline":true,"label":"release","permalink":"/blog/tags/release"},{"inline":true,"label":"buildbarn","permalink":"/blog/tags/buildbarn"}],"readingTime":3.375,"hasTruncateMarker":false,"authors":[{"name":"Benjamin Ingberg","imageURL":"/img/benjamin-avatar.png","key":"benjamin","page":null}],"frontMatter":{"slug":"bb-deployments-updates-2023-02","title":"Updates to Buildbarn deployment repo as of Febuary 2023","authors":"benjamin","tags":["release","buildbarn"]},"unlisted":false,"prevItem":{"title":"Buildbarn Block Sizes","permalink":"/blog/buildbarn-block-sizes"},"nextItem":{"title":"Bazel 6 Errors when using Build without the Bytes","permalink":"/blog/bazel-6-errors-build-without-the-bytes"}},"content":"The example configuration project for buildbarn\\n[bb-deployments](https://github.com/buildbarn/bb-deployments)\\nhas gotten updates.\\n\\nThis is a continuation of the\\n[updates from last year article](/blog/bb-deploy-updates-2022-04)\\nand is a high level summary of what has happened since April 2022 up to 2023-02-16.\\n\\n## Let ReferenceExpandingBlobAccess support GCS\\n\\nReferenceExpandingBlobAccess already supports S3 so support was extended to Google Cloud Storage buckets.\\n\\n## Support for prefetching Virtual Filesystems\\n\\nRunning workers with Fuse allows inputs for an action\\nto be downloaded on demand.\\nThis significantly reduces the amount of data\\nthat gets sent in order to run overspecified actions.\\nThis however leads to poor performance for actions\\nwhich reads a lot of their inputs synchronously.\\n\\nWith the prefetcher most of these actions can be recognized\\nand data which is likely to be needed\\ncan be downloaded ahead of time.\\n\\n## Support for sha256tree\\n\\nBuildbarn has added support for\\n[sha256tree](https://github.com/bazelbuild/remote-apis/pull/235)\\nwhich uses sha256 hashing over a tree structure similar to blake3.\\n\\nThis algorithm will allow large CAS objects to be chunked and decompositioned\\nwith guaranteed data integrity while still using sha256 hardware instructions.\\n\\n## Completeness checking now streams REv2 Tree objects\\n\\nThis change introduces a small change to the configuration schema. If you previous had this:\\n```\\nbackend: { completenessChecking: ... },\\n```\\nYou will now need to write something along these lines:\\n```\\nbackend: {\\n    completenessChecking: {\\n        backend: ...,\\n        maximumTotalTreeSizeBytes: 64 * 1024 * 1024,\\n    },\\n},\\n```\\n\\nSee also the\\n[bb-storage commit 1b84fa8](https://github.com/buildbarn/bb-storage/commit/1b84fa824dc60e77776ce50e05c549fdf20c089b).\\n\\n## Postponed healthy service status\\n\\nThe healthy and serving status,\\ni.e. HTTP `/-/healthy` and\\n[grpc_health_v1.HealthCheckResponse_SERVING](https://pkg.go.dev/google.golang.org/grpc/health/grpc_health_v1#HealthCheckResponse_ServingStatus),\\nare now postponed until the whole service is up and running.\\nBefore, the healthy status was potentially reported before starting to listen to the gRPC ports.\\nKubernetes will now wait until the service is up before forwarding connections to it.\\n\\n## Server keepalive parameter options\\n\\nThe option `buildbarn.configuration.grpc.ServerConfiguration.keepalive_parameters` can be used for L4 load balancing,\\nto control when to ask clients to reconnect.\\nFor default values, see\\n[keepalive.ServerParameters](https://pkg.go.dev/google.golang.org/grpc@v1.49.0/keepalive#ServerParameters).\\n\\n## Graceful termination of `LocalBlobAccess`\\n\\nWhen `SIGTERM` or `SIGINT` is received, the `LocalBlobAccess` now synchronize data to disk before shutting down.\\nDeployments using persistent storage will no longer observe loss of data when restarting the `bb_storage` services.\\n\\n## Non-sector Aligned Writes to Block Device\\n\\nUsing sector aligned storage is wasteful for the action cache where the messages are typically very small.\\nBuildbarn can now fill all the gaps when writing, making storage more efficient.\\n\\n## DAG Shaped BlobAccess Configuration\\n\\nInstead of a tree shaped BlobAccess configuration, the `with_labels` notation allows a directed acyclic graph.\\nSee also the\\n[bb-storage commit cc295ad](https://github.com/buildbarn/bb-storage/commit/cc295adc0f05cd579d48a65325ce54b54331c6a6).\\n\\n## NFSv4 as worker filesystem\\n\\nThe `bb_worker` can now supply the working directory for `bb_runner` using NFSv4.\\nPreviously, FUSE and hard linking files from the worker cache were the only two options.\\nThis addition was mainly done to overcome the poor FUSE support on macOS.\\n\\nThe NFSv4 server in `bb_worker` only supports macOS at the moment.\\nNo effort has been spent to write custom mount logic for other systems yet.\\n\\n## Specify `forwardMetadata` with a JMESPath\\n\\nMetadata forwarding is now more flexible, the JMESPath expressions can for example add authorization result data.\\nThe format is described in\\n[grpc.proto](https://github.com/buildbarn/bb-storage/blob/0c2fcad5872b0fef47bb5bee8aba9518dc2fe465/pkg/proto/configuration/grpc/grpc.proto#L55-L93).\\n\\nA common use case is to replace\\n```jsonnet\\n{\\n    forwardMetadata: [\\"build.bazel.remote.execution.v2.requestmetadata-bin\\"],\\n}\\n```\\nwith\\n```jsonnet\\n{\\n    addMetadataJmespathExpression: \'{\\n        \\"build.bazel.remote.execution.v2.requestmetadata-bin\\":\\n            incomingGRPCMetadata.\\"build.bazel.remote.execution.v2.requestmetadata-bin\\"\\n    }\',\\n}\\n```\\n\\n## Tracing: Deprecate the Jaeger collector span exporter\\n\\nThis option is deprecated, as Jaeger 1.35 and later provide native support for the OpenTelemetry protocol.\\n\\n## `bb-deployments` Ubuntu 22.04 Example Runner Image\\n\\nThe [rbe_autoconfig](https://github.com/bazelbuild/bazel-toolchains/blob/4.0.0/rules/rbe_repo.bzl#L896)\\nin [bazel-toolchains](https://github.com/bazelbuild/bazel-toolchains)\\nhas been deprecated. In bb-deployments it has been replaced by the\\n[Act](https://github.com/nektos/act/blob/master/IMAGES.md) image\\n[ghcr.io/catthehacker/ubuntu:act-22.04](https://github.com/catthehacker/docker_images),\\ndistributed by [catthehacker](https://github.com/catthehacker/docker_images),\\nused for running GitHub Actions locally under Ubuntu 22.04.\\n\\n## `bb-deployments` Integration Tests\\n\\nThe [bare deployment](https://github.com/buildbarn/bb-deployments/tree/ce123473f27290648d1e56f7072468eb6b67fefb/bare) and\\n[Docker Compose deployment](https://github.com/buildbarn/bb-deployments/tree/ce123473f27290648d1e56f7072468eb6b67fefb/docker-compose)\\nhave now got [tests scripts](https://github.com/buildbarn/bb-deployments/tree/ce123473f27290648d1e56f7072468eb6b67fefb/tools)\\nthat builds and tests `@abseil-hello//:hello_test` remotely, shuts down and then checks for 100% cache hit after restart.\\nAnother CI test is checking for minimal differences between the Docker Compose deployment and\\nthe [Kubernetes deployment](https://github.com/buildbarn/bb-deployments/tree/ce123473f27290648d1e56f7072468eb6b67fefb/kubernetes).\\n\\nIf there are any other changes you feel deserve a mention\\nfeel free to submit a pull request at github using the link below."},{"id":"bazel-6-errors-build-without-the-bytes","metadata":{"permalink":"/blog/bazel-6-errors-build-without-the-bytes","editUrl":"https://github.com/meroton/docs/edit/main/blog/2023-02-07-bazel-errors-when-using-bazel-6.mdx","source":"@site/blog/2023-02-07-bazel-errors-when-using-bazel-6.mdx","title":"Bazel 6 Errors when using Build without the Bytes","description":"_ UPDATE:  Bazel has a workaround for this issue","date":"2023-02-07T00:00:00.000Z","tags":[{"inline":true,"label":"bazel","permalink":"/blog/tags/bazel"},{"inline":true,"label":"bugs","permalink":"/blog/tags/bugs"}],"readingTime":3.285,"hasTruncateMarker":false,"authors":[{"name":"Benjamin Ingberg","imageURL":"/img/benjamin-avatar.png","key":"benjamin","page":null}],"frontMatter":{"slug":"bazel-6-errors-build-without-the-bytes","title":"Bazel 6 Errors when using Build without the Bytes","authors":"benjamin","tags":["bazel","bugs"]},"unlisted":false,"prevItem":{"title":"Updates to Buildbarn deployment repo as of Febuary 2023","permalink":"/blog/bb-deployments-updates-2023-02"},"nextItem":{"title":"BuildBar at the Meroton Office","permalink":"/blog/buildbar-at-meroton-office"}},"content":"_** UPDATE: ** Bazel has a workaround for this issue\\npreventing the permanent build failure loop from 6.1.0 and\\na proper fix with the introduction of\\n[`--experimental_remote_cache_ttl`](https://bazel.build/reference/command-line-reference#flag--experimental_remote_cache_ttl)\\nin Bazel 7_\\n\\n---\\n\\nStarting from v6.0.0, Bazel crashes when building without the bytes.\\nBecause it sets `--experimental_action_cache_store_output_metadata`\\nwhen using `--remote_download_minimal` or `--remote_download_toplevel`.\\n\\nEffectively this leads to Bazel getting stuck in a build failure loop\\nwhen your remote cache evicts an item you need from the cache.\\n\\n```console\\ndeveloper@machine:~$ bazel test @abseil-hello//:hello_test --remote_download_\\nminimal\\n\\n[0 / 6] [Prepa] BazelWorkspaceStatusAction stable-status.txt\\nERROR: /home/developer/.cache/bazel/_bazel_developer/139b99b96c4ab6cba5122193\\n1a36e346/external/abseil-hello/BUILD.bazel:26:8: Linking external/abseil-hell\\no/hello_test failed: (Exit 34): 42 errors during bulk transfer:\\njava.io.FileNotFoundException: /home/developer/.cache/bazel/_bazel_developer/\\n139b99b96c4ab6cba51221931a36e346/execroot/cache_test/bazel-out/k8-fastbuild/b\\nin/external/com_google_absl/absl/base/_objs/base/spinlock.pic.o (No such file\\n or directory)\\n...\\nTarget @abseil-hello//:hello_test failed to build\\nUse --verbose_failures to see the command lines of failed build steps.\\nINFO: Elapsed time: 3.820s, Critical Path: 0.88s\\nINFO: 5 processes: 4 internal, 1 remote.\\nFAILED: Build did NOT complete successfully\\n@abseil-hello//:hello_test                                   FAILED TO BUILD\\n```\\n\\nThe key here is **(Exit 34): xx errors during bulk transfer**.\\n34 is Bazel\'s error code for Remote Error.\\n\\nThe recommended solution is to set the flag explicitly to false,\\nwith `--experimental_action_cache_store_output_metadata=false`.\\nTo quickly solve the issue on your local machine you can run `bazel clean`.\\nHowever, this will just push the error into the future.\\n\\nThe bug is independent of which remote cache system you use\\nand is tracked at [GitHub](https://github.com/bazelbuild/bazel/issues/17366).\\n\\n## Background\\n\\nWhen performing an analysis of what to build\\nBazel will ask the remote cache which items have already been built.\\nBazel will only schedule build actions for items\\nthat do not already exist in the cache.\\nIf running a build without the bytes[^1]\\nthe intermediary results will not be downloaded to the client.\\n\\nShould the cached items be evicted\\nthen Bazel will run into an unrecoverable error.\\nIt wants the remote system to perform an action using inputs from the cache,\\nbut they have disappeared.\\nAnd Bazel can not upload them,\\nas they were never downloaded to the client.\\nThe build would then dutifully crash\\n(some work has been put into trying to\\n[resolve this on the bazel side](https://groups.google.com/g/bazel-dev/c/WwNN4kiYSpc)\\nbut it has not been considered a priority).\\n\\nThis puts an implicit requirement on the remote cache implementation.\\nArtifacts need to be saved for as long as Bazel needs them.\\nThe problem here is that this is an undefined period of time.\\nBazel will not proactively check if the item still exists,\\nnor in any other manner inform the cache that\\nit will need the item in the future.\\n\\n## Before v6.0.0\\n\\nBazel tied the lifetime of which items already exists in the cache\\n(the existence cache)\\nto the analysis cache.\\nWhenever the analysis cache was purged it would also drop the existence cache.\\n\\nThe analysis cache is purged quite frequently.\\nIt would therefore be rare in practice,\\nthat the existence cache would be out of date.\\nFurthermore, since the existence cache was an in-memory cache,\\nBazel crashing would forcefully evict the existence cache.\\nThereby fixing the issue.\\n\\n## After v6.0.0\\n\\nWith the\\n`--experimental_action_cache_store_output_metadata` flag enabled by default\\nthe existence cache is instead committed to disk and\\nnever dropped during normal operation.\\n\\nThis means two things:\\n\\n1. The implied requirement on the remote cache is effectively infinite.\\n2. Should this requirement not be met the build will fail.\\n   And since the existence cache is committed to disk Bazel will just\\n   fail again the next time you run it.\\n\\nCurrently the only user-facing way of purging the existence cache\\nis to run `bazel clean`.\\nWhich is generally considered an anti-pattern.\\n\\nIf you are using the [bb-clientd](https://github.com/buildbarn/bb-clientd#-to-perform-remote-builds-without-the-bytes) `--remote_output_service`\\nto run builds without the bytes\\n(an alternative strategy to `--remote_download_minimal`)\\nthis will not affect you.\\n\\n[^1]:\\n    When using Bazel with remote execution\\n    remote builds are run in a remote server cluster.\\n    There is therefore no need for each developer\\n    to download the partial results of build.\\n    Bazel calls this feature\\n    [Remote Builds Without the Bytes](https://blog.bazel.build/2019/05/07/builds-without-bytes.html).\\n    The progress of the feature can be tracked at\\n    [GitHub](https://github.com/bazelbuild/bazel/issues/6862)."},{"id":"buildbar-at-meroton-office","metadata":{"permalink":"/blog/buildbar-at-meroton-office","editUrl":"https://github.com/meroton/docs/edit/main/blog/2022-11-24-build-bar-at-meroton-office.mdx","source":"@site/blog/2022-11-24-build-bar-at-meroton-office.mdx","title":"BuildBar at the Meroton Office","description":"After BazelCon we\'ve all gotten a bit giddy and you might feel excited how the information presented at BazelCon might impact your development workflow.","date":"2022-11-24T00:00:00.000Z","tags":[{"inline":true,"label":"meroton","permalink":"/blog/tags/meroton"},{"inline":true,"label":"afterwork","permalink":"/blog/tags/afterwork"}],"readingTime":0.57,"hasTruncateMarker":false,"authors":[{"name":"Benjamin Ingberg","imageURL":"/img/benjamin-avatar.png","key":"benjamin","page":null}],"frontMatter":{"slug":"buildbar-at-meroton-office","title":"BuildBar at the Meroton Office","authors":"benjamin","tags":["meroton","afterwork"]},"unlisted":false,"prevItem":{"title":"Bazel 6 Errors when using Build without the Bytes","permalink":"/blog/bazel-6-errors-build-without-the-bytes"},"nextItem":{"title":"Remote Executors for the Free Environment","permalink":"/blog/remote-executors-for-free-tier"}},"content":"After BazelCon we\'ve all gotten a bit giddy and you might feel excited how the information presented at BazelCon might impact your development workflow.\\nFor that purpose we\'re inviting everyone in the wider bazel community to an open BuildBar at the Meroton offices.\\n\\nCome over and digest BazelCon with high level technical discussions of the talks,\\ngreat company, a pleasant atmosphere and also beer.\\n\\nFeel welcome to come over this Thursday the first of December from 16 to 20.\\n\\n## Directions\\n\\nYou\'ll find us at our Link\xf6ping offices at Fridtunagatan 33. Currently there is some construction but follow the red lines and you\'ll be fine.\\n\\n<figure>\\n  <img alt=\\"\\" src=\\"/img/office_map.webp\\" />\\n  <figcaption>Fridtunagatan 33 Link\xf6ping</figcaption>\\n</figure>"},{"id":"remote-executors-for-free-tier","metadata":{"permalink":"/blog/remote-executors-for-free-tier","editUrl":"https://github.com/meroton/docs/edit/main/blog/2022-10-13-remote-executors-for-free-tier.mdx","source":"@site/blog/2022-10-13-remote-executors-for-free-tier.mdx","title":"Remote Executors for the Free Environment","description":"We\'ve performed some updates to the free tier and our pricing model.","date":"2022-10-13T00:00:00.000Z","tags":[{"inline":true,"label":"meroton","permalink":"/blog/tags/meroton"},{"inline":true,"label":"remote execution","permalink":"/blog/tags/remote-execution"},{"inline":true,"label":"cloud","permalink":"/blog/tags/cloud"},{"inline":true,"label":"free tier","permalink":"/blog/tags/free-tier"},{"inline":true,"label":"starter tier","permalink":"/blog/tags/starter-tier"}],"readingTime":1.575,"hasTruncateMarker":false,"authors":[{"name":"Benjamin Ingberg","imageURL":"/img/benjamin-avatar.png","key":"benjamin","page":null}],"frontMatter":{"slug":"remote-executors-for-free-tier","title":"Remote Executors for the Free Environment","authors":"benjamin","tags":["meroton","remote execution","cloud","free tier","starter tier"]},"unlisted":false,"prevItem":{"title":"BuildBar at the Meroton Office","permalink":"/blog/buildbar-at-meroton-office"},"nextItem":{"title":"Tips, Tricks & Non-Deterministic Builds","permalink":"/blog/tips-trix-and-nondeterminism"}},"content":"We\'ve performed some updates to the free tier and our pricing model.\\n\\n## Shared Cache\\n\\nThe free tier has been upgraded into an environment with a 1TB cache.\\nThis means that you can use the free tier without worrying about hitting any limits or setup process.\\n\\nDo note that while the cached items will only be accessible with the correct api keys,\\nthe storage area can be reclaimed by anyone.\\nI.e. as the cache becomes full your items might be dropped.\\n\\nWith the current churn we expect any items in the cache last at least a week.\\nHowever, you should always treat items in the cache as something which might be dropped at any moment.\\nThe purpose and design of the cache is to maximize build performance, not to provide storage.\\n\\n## Shared executors\\n\\nNew for the free environment is the introduction of remote execution,\\nthis was previously only available for paying customers.\\n\\nIf you\'re using bazel you can simply add the `--remote_executor=<...>` flag and your builds will be done remotely.\\n\\nThe free environment has access to 64 shared executors.\\n\\n## Starter tier\\n\\nIf you need dedicated storage for evaluation purposes we also offer a starter tier.\\nThe starter tier is a streamlined environment with 100 GB of dedicated cache and access to the same 64 executors as the free tier.\\n\\nThis allows you to try out remote execution and caching without being disturbed by others.\\nWhile the 100GB dedicated cache will only be used by you and therefore not be overwritten by anyone else\'s build,\\nthe cache is still a cache and the system will still drop the cache entries if it determines it is useful for maximizing performance.\\n\\n## Need more executors?\\n\\nAt the moment the starter tier has a fixed amount of shared executors.\\nIf you need a scalable solution contact us for setting up a custom Buildbarn environment of any size."},{"id":"tips-trix-and-nondeterminism","metadata":{"permalink":"/blog/tips-trix-and-nondeterminism","editUrl":"https://github.com/meroton/docs/edit/main/blog/2022-08-28-tips-trix-and-non-deterministic-builds.mdx","source":"@site/blog/2022-08-28-tips-trix-and-non-deterministic-builds.mdx","title":"Tips, Tricks & Non-Deterministic Builds","description":"When you have a remote build and cache cluster it can sometimes be hard to track down what exactly is using all of your building resources. To help with this we have started a tips and trix section in the documentation where we will share methods we use to debug and resolve slow builds.","date":"2022-08-28T00:00:00.000Z","tags":[{"inline":true,"label":"meroton","permalink":"/blog/tags/meroton"},{"inline":true,"label":"bazel","permalink":"/blog/tags/bazel"},{"inline":true,"label":"optimizing","permalink":"/blog/tags/optimizing"}],"readingTime":1.21,"hasTruncateMarker":false,"authors":[{"name":"Benjamin Ingberg","imageURL":"/img/benjamin-avatar.png","key":"benjamin","page":null}],"frontMatter":{"slug":"tips-trix-and-nondeterminism","title":"Tips, Tricks & Non-Deterministic Builds","authors":"benjamin","tags":["meroton","bazel","optimizing"]},"unlisted":false,"prevItem":{"title":"Remote Executors for the Free Environment","permalink":"/blog/remote-executors-for-free-tier"},"nextItem":{"title":"Updates to Buildbarn deployment repo as of April 2022","permalink":"/blog/bb-deploy-updates-2022-04"}},"content":"When you have a remote build and cache cluster it can sometimes be hard to track down what exactly is using all of your building resources. To help with this we have started a tips and trix section in the documentation where we will share methods we use to debug and resolve slow builds.\\n\\nThe first section is about build non-determinism. Ideally your build actions should produce the same output when run with the same input, in practice this is sometimes not the case. If you are lucky a non-deterministic action won\'t be noticed since the inputs for the non-deterministic action is unchanged it won\'t be rebuilt.\\n\\nIf you\'re not so lucky the non-determinism stems from a bug in the implementation and you should definitely pay attention to them. But how do you know which if any actions are non-deterministic?\\n\\nThis is not trivial but we have added [a server side feature](/docs/tips/non-deterministic-builds) which allows detection of non-determinism with virtually no effort on your part.\\n\\nOnce activated it reruns a configured fraction of your actions and automatically flags them if they produce different outputs. The scheduling is done outside of your bazel invocation so your build throughput will be unaffected at the cost of an increase in the number of resources consumed. We suggest 1% which will only increase your resource use by a trivial amount but you could of course set it to 100% which would double the cost of your builds."},{"id":"bb-deploy-updates-2022-04","metadata":{"permalink":"/blog/bb-deploy-updates-2022-04","editUrl":"https://github.com/meroton/docs/edit/main/blog/2022-05-04-updates-to-bb-deploy.mdx","source":"@site/blog/2022-05-04-updates-to-bb-deploy.mdx","title":"Updates to Buildbarn deployment repo as of April 2022","description":"The sample configuration project for Buildbarn was recently updated after a long hiatus. As an aid for people to understand which changes have been done see the following high level summary.","date":"2022-05-04T00:00:00.000Z","tags":[{"inline":true,"label":"release","permalink":"/blog/tags/release"},{"inline":true,"label":"buildbarn","permalink":"/blog/tags/buildbarn"}],"readingTime":1.63,"hasTruncateMarker":false,"authors":[{"name":"Benjamin Ingberg","imageURL":"/img/benjamin-avatar.png","key":"benjamin","page":null}],"frontMatter":{"slug":"bb-deploy-updates-2022-04","title":"Updates to Buildbarn deployment repo as of April 2022","authors":"benjamin","tags":["release","buildbarn"]},"unlisted":false,"prevItem":{"title":"Tips, Tricks & Non-Deterministic Builds","permalink":"/blog/tips-trix-and-nondeterminism"},"nextItem":{"title":"Purpose of the Articles","permalink":"/blog/about"}},"content":"The [sample configuration project for Buildbarn](https://github.com/buildbarn/bb-deployments) was recently updated after a long hiatus. As an aid for people to understand which changes have been done see the following high level summary.\\n\\n## April 2022 Updates\\n\\nThis includes updates to Buildbarn since December 2020.\\n\\n### Authorizer Overhaul\\n\\nAuthorizers have been rehauled to be more flexible it is now part of each individual cache and execution configuration.\\n\\nUsing a JWT authorization bearer token has been added as an authorization method.\\n\\n### Hierarchical Blob Access\\n\\nUsing hierarchical blob access allows blobs in instance name `foo/bar` to be accessed from instance `foo/bar/baz` but not instance `foo` or `foo/qux`.\\n\\n### Action Result Expiration\\n\\nAn expiry can be added to action result which lets the action cache purge the result of an exection that was performed too far in the past. This can be used to ensure that all targets are rebuilt periodically even if they are accessed frequently enough to not normally be purged from the cache.\\n\\n### Read Only Cache Replicas\\n\\nCache read traffic can now be sent to a read-only replica which is periodically probed for availability.\\n\\n### Concurrency Limiting Blob Replication\\n\\nLimit the number of concurrent replications to prevent network starvation\\n\\n### Run Commands as Another User\\n\\nAllows the commands to be run as a different user, on most platforms this means the bb-runner instance must run as root.\\n\\n### Size Class Analysis\\n\\nAllows executors of different size classes to be used, the scheduler will attempt to utilize executors efficiently but there is an inherent tradeof between throughput and latency. Once configured the scheduler will automatically attempt to keep track of which actions are best run on which executors.\\n\\n### Execution Routing Policy\\n\\nThe scheduler accepts an execution routing policy configuration that allows it to determine how to defer builds to different executors.\\n\\nIf you see any other changes you feel should get a mention feel free to submit a pull request at github using the link below."},{"id":"about","metadata":{"permalink":"/blog/about","editUrl":"https://github.com/meroton/docs/edit/main/blog/2022-02-22-about.mdx","source":"@site/blog/2022-02-22-about.mdx","title":"Purpose of the Articles","description":"The purpose of these articles is to have a freeform area discussing ideas, technical issues, solutions and news in an indepth relaxed manner. It is not to serve as reference material, structured reference material should be available in the documentation section.","date":"2022-02-22T00:00:00.000Z","tags":[{"inline":true,"label":"meroton","permalink":"/blog/tags/meroton"}],"readingTime":0.505,"hasTruncateMarker":false,"authors":[{"name":"Benjamin Ingberg","imageURL":"/img/benjamin-avatar.png","key":"benjamin","page":null}],"frontMatter":{"slug":"about","title":"Purpose of the Articles","authors":"benjamin","tags":["meroton"]},"unlisted":false,"prevItem":{"title":"Updates to Buildbarn deployment repo as of April 2022","permalink":"/blog/bb-deploy-updates-2022-04"}},"content":"The purpose of these articles is to have a freeform area discussing ideas, technical issues, solutions and news in an indepth relaxed manner. It is not to serve as reference material, structured reference material should be available in the documentation section.\\n\\nThe article format allows more in depth on discussions for reacurring subjects. In contrast to the documentation published articles aren\'t changed, if the subject requires a revisit in the future then we publish a new post and add references to the old.\\n\\nIf you see any errors feel free to submit a pull request at github using the link below."}]}}')}}]);